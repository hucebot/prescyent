{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beforehand\n",
    "\n",
    "## Presentation of the lib ?\n",
    "\n",
    "## Pre requisites\n",
    "\n",
    "Note that you may want to run this jupyter notebook in a virtual env !  \n",
    "To do so, create your environment with virtualenv or conda, activate it, install ipykernel and add your virtual environment to the jupyter kernels.  \n",
    "You should find all the necessary information here: https://janakiev.com/blog/jupyter-virtual-envs/  \n",
    "\n",
    "Here is what I personally did:  \n",
    "\n",
    "<details>\n",
    "    <summary>Click once on <font color=\"blue\"><b>this text</b></font> to show/hide the commands I used</summary>\n",
    "\n",
    "```bash\n",
    "    virtualenv .venv\n",
    "    source .venv/bin/activate\n",
    "    pip install ipykernel\n",
    "    python -m ipykernel install --name=venv_prescyent\n",
    "```\n",
    "</details>\n",
    "\n",
    "\n",
    "You should now edit and run this jupyter notebook in your browser, by running jupyter in your terminal with:  `jupyter notebook`  \n",
    "Or also run jupyters notebooks directly in vscode, selecting your newly created kernel instead of the current selection in the top right corner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "\n",
    "## Install the lib and download a dataset\n",
    "\n",
    "You should have all necessary information in the readme, and if not it's the perfect occasion to tell me !  \n",
    "Here we want to install the library from pypi, and load a dataset  \n",
    "Note that the pypi install of PreScyent install also all of its dependencies, including torch and cuda which can be long to install. You may want to install a custom version of torch beforehand that would still match the dependencies of PreScyent, so any torch above 2.0 (and bellow 3.0 if you are doing this tutorial from the future.)  \n",
    "In that case, choose a version of pytroch for your environment here: https://pytorch.org/get-started/locally/  \n",
    "\n",
    "\n",
    "The dataset we want to download is the TeleopIcub Dataset that you can find here: https://zenodo.org/records/5913573  \n",
    "or directly in its .hdf5 format here https://gitlab.inria.fr/hucebot/datasets/andydata-lab-prescientteleopicub (if you have the access rights)  \n",
    "\n",
    "If you have the original data from the zenodo website, you have to pre process it into the library's format to be able to load it and use it in the lib.  \n",
    "Again, please check the readme for the instructions !  \n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Click once on <font color=\"blue\"><b>this text</b></font> to show/hide the commands I used</summary>\n",
    "\n",
    "In the virualenv, install a specific version of torch instead of letting the library choose from its dependencies\n",
    "```bash\n",
    "    pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "```\n",
    "\n",
    "Install the lib from pypi\n",
    "```bash\n",
    "    pip install prescyent\n",
    "```\n",
    "\n",
    "Download and prepare dataset\n",
    "```bash\n",
    "    wget https://zenodo.org/records/5913573/files/AndyData-lab-prescientTeleopICub.zip\n",
    "    unzip AndyData-lab-prescientTeleopICub.zip -d AndyData-lab-prescientTeleopICub/\n",
    "    wget https://raw.githubusercontent.com/hucebot/prescyent/refs/heads/main/dataset_preprocessing/teleopicubdataset_to_hdf5.py\n",
    "    python teleopicubdataset_to_hdf5.py --data_path AndyData-lab-prescientTeleopICub/\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meet the Dataset and Trajectory\n",
    "\n",
    "Load the downloaded and processed dataset using the corresponding dataset class  \n",
    "\n",
    "\n",
    "We use Config classes for our main classes such as Datasets, Predictors, Scalers, or TrainingConfig for the Predictor's trainer  \n",
    "Such classes allows us to define default values and give some constraints or type hints about the possible inputs  \n",
    "If you use a code editor with auto_completion you'll have default values and types indicated, you can also refer to the user documentation for each config file here:  \n",
    "https://hucebot.github.io/prescyent/configuration_files.html  \n",
    "\n",
    "\n",
    "Update the dataset's config and see the corresponding generated tensor pairs and plots using the functions bellow !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from prescyent.dataset import TeleopIcubDataset, TeleopIcubDatasetConfig\n",
    "from prescyent.evaluator.plotting import plot_trajectory_feature_wise\n",
    "\n",
    "\n",
    "# You may want to update your dataset path depending on where your hdf5 file is:\n",
    "HDF5_PATH = \"data/datasets/AndyData-lab-prescientTeleopICub.hdf5\"\n",
    "\n",
    "dataset_config = TeleopIcubDatasetConfig(\n",
    "    hdf5_path=HDF5_PATH,\n",
    "    batch_size=256,\n",
    "    # Change the configuration of the dataset here !\n",
    "    )\n",
    "dataset = TeleopIcubDataset(dataset_config)\n",
    "\n",
    "input_tensor, context, output_tensor = next(iter(dataset.train_dataloader()))\n",
    "\n",
    "# Show shapes of data from the dataloaders as it'll be seen for the models\n",
    "print(f\"#######################\")\n",
    "print(f\"TRAINING TENSOR SHAPES:\")\n",
    "print(f\"#######################\")\n",
    "print(f\"input_tensor as shapes {input_tensor.shape}\")\n",
    "print(f\"output_tensor as shapes {output_tensor.shape}\")\n",
    "for context_key, context_tensor in context.items():\n",
    "    print(f\"context {context_key} as shapes {context_tensor.shape}\")\n",
    "print(f\"#######################\")\n",
    "\n",
    "# Plot data from a test trajectory itself\n",
    "plot_trajectory_feature_wise(dataset.trajectories.test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Baselines on this dataset\n",
    "\n",
    "Now that you loaded a dataset, you want to run some predictors over it\n",
    "Let's meet the predictors with a very simple baseline, such as the ConstantPredictor or DelayedPredictor\n",
    "Instantiate one of theses baselines bellow and see the resulting prediction plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_prediction_feature_wise\n",
    "\n",
    "# import and instantiate one baseline here:\n",
    "\n",
    "from prescyent.predictor import ConstantPredictor, PredictorConfig\n",
    "\n",
    "baseline = ConstantPredictor(PredictorConfig(dataset_config=dataset.config))\n",
    "test_traj = dataset.trajectories.test[0]\n",
    "\n",
    "\n",
    "# remember that the future size if the number of predicted frames\n",
    "# if you want to test a prediction at a S second future, you can use:\n",
    "S = 2.5\n",
    "future_size = int(S * test_traj.frequency)\n",
    "\n",
    "# usually we set the same future_size as the dataset's config:\n",
    "# future_size = dataset.config.future_size\n",
    "# but you can play with this value and baselines to update the produced plot\n",
    "\n",
    "# we create a new predicted trajectory from a given predictor, built from the last predicted frame at each timestep\n",
    "baseline_traj, baseline_offset = baseline.predict_trajectory(\n",
    "    test_traj, future_size=future_size\n",
    ")\n",
    "# subset a truth trajectory from thge original traj if needed, to compare fairly with prediction\n",
    "truth_traj = test_traj.create_subtraj(\n",
    "    dataset.config.out_points, dataset.config.out_features\n",
    ")\n",
    "title = f\"{baseline}_over_{truth_traj.title}\"\n",
    "# plot prediction along truth\n",
    "\n",
    "plot_prediction_feature_wise(\n",
    "    truth_traj,\n",
    "    baseline_traj,\n",
    "    offset=baseline_offset,\n",
    ")\n",
    "\n",
    "# Notice that the predicted trajectory doesn't start at T = future_size\n",
    "# Because we need to have an input of size history_size before predicting an output of size future_size\n",
    "# So actually the first predicted frame is at T = history_size + future_size - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train a Predictor model and save it\n",
    "\n",
    "Using our simplest architecture, the MlpPredictor we'll see how to train and save a ML Predictor, using high level methods based on the pytorch_lightning syntax.  \n",
    "\n",
    "Here you'll see that each of our ML Predictors as their own specific PredictorConfig, as they allow to customize their layers and behavior.  \n",
    "In addition to their config, to allow some training, you'll have to define a TrainingConfig object, again customizing the training process (number of epochs, early stopping patience, learning rate...)  \n",
    "\n",
    "It's also the moment to introduce the enums, such as LossFunctions or LearningTypes.  \n",
    "They are a standard we chose over Literals to describe a set of finite possibilities for a given config value, and define cleaner conditions based on theses values in the code instead of manipulating strings or another type.\n",
    "You'll find all of them importable from `prescyent.utils.enums`.  \n",
    "And more details about their values in the doc here: https://hucebot.github.io/prescyent/configuration_files.html  \n",
    "\n",
    "Once your model is trained, or during its training, you can monitor many training metrics using using tensorboard and providing the path to the directory where the model logs (defined by its configs' `save_path` argument, which default's value is \"data/models\"):\n",
    "`tensorboard --logdir data/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from prescyent.predictor import MlpPredictor, MlpConfig, TrainingConfig\n",
    "from prescyent.scaler import ScalerConfig\n",
    "from prescyent.utils.enums import LossFunctions, Scalers, TrajectoryDimensions, LearningTypes\n",
    "\n",
    "\n",
    "# -- Configure scaler\n",
    "scaler_config = ScalerConfig(\n",
    "    do_feature_wise_scaling=True,\n",
    "    scaler=Scalers.STANDARDIZATION,\n",
    "    scaling_axis=TrajectoryDimensions.TEMPORAL,\n",
    ")\n",
    "# -- Init predictor\n",
    "print(\"Initializing predictor...\", end=\" \")\n",
    "config = MlpConfig(\n",
    "    dataset_config=dataset_config,\n",
    "    context_size=dataset.context_size_sum,\n",
    "    scaler_config=scaler_config,  # pass the scaler config to the predictor, which owns the scaling functions\n",
    "    hidden_size=128,\n",
    "    num_layers=4,\n",
    "    deriv_on_last_frame=True,\n",
    "    loss_fn=LossFunctions.MTDLOSS,\n",
    ")\n",
    "predictor = MlpPredictor(config=config)\n",
    "print(\"OK\")\n",
    "\n",
    "# Train\n",
    "training_config = TrainingConfig(\n",
    "    max_epochs=1,  # Maximum number of training epochs\n",
    "    devices=\"auto\",  # Chose the best available devices (see lightning documentation for more)\n",
    "    accelerator=\"auto\",  # Chose the best available accelerator (see lightning documentation for more)\n",
    "    lr=0.0001,  # The learning rate\n",
    "    early_stopping_patience=10,  # We'll stop the training before max_epochs if the validation loss doesn't improve for 10 epochs\n",
    ")\n",
    "\n",
    "# Scaler is also trained by the predictor's method !\n",
    "predictor.train(dataset, training_config)\n",
    "\n",
    "# Save the predictor in an explicit directory describing the settings of the experiment\n",
    "xp_dir = (\n",
    "    Path( \"data\")\n",
    "    / \"models\"\n",
    "    / f\"{dataset.DATASET_NAME}\"\n",
    "    / f\"h{dataset_config.history_size}_f{dataset_config.future_size}_{dataset.frequency}hz\"\n",
    ")\n",
    "model_dir = xp_dir / f\"{predictor.name}\" / f\"version_{predictor.version}\"\n",
    "print(\"Model directory:\", model_dir)\n",
    "predictor.save(model_dir, rm_log_path=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load a model\n",
    "\n",
    "You can load a Predictor from disk using its static method `load_pretrained`. You must provide as argument the path to root directory of the model or directly to its config.json file.  \n",
    "Also when loading a Predictor from disk, you may choose on which `torch.device` you want to load your model's weights, by passing the device as an argument to the `load_pretrained` method of AutoPredictor or Predictor.  \n",
    "Remember that choosing the device is made through the `TrainingConfig.accelerator` attribute when you are creating a model from scratch.  \n",
    "The AutoPredictor class allows to load or build a Predictor based on its config file. The class has to be a class from the library in order for the AutoPredictor to function and recognize it (see in the user doc how to create a new predictor and add it to the AutoPredictor class).  \n",
    "It is perfect to generate an evaluation script that is agnostic to the actual class of predictor.  \n",
    "\n",
    "\n",
    "Note also that we still use the same loaded dataset, but the AutoDataset class also exists for the same purpose: reloading a Dataset used from a dataset_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.auto_predictor import AutoPredictor\n",
    "\n",
    "loaded_predictor = MlpPredictor.load_pretrained(model_dir, device=\"cpu\")\n",
    "loaded_predictor.describe()\n",
    "loaded_predictor = AutoPredictor.load_pretrained(model_dir / 'config.json', device=\"cpu\")\n",
    "loaded_predictor.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Predictor\n",
    "\n",
    "The metrics\n",
    "We've seen qualitative evaluations with the previous work, here we'll introduce some quantitative metrics\n",
    "First, we'll use the `test` method of the Predictor class to run the predictor over the whole test dataloader and return some metrics:\n",
    "ADE\n",
    "FDE\n",
    "MPJPE\n",
    "Again you can monitor the results of such test method using tensorboard\n",
    "\n",
    "We introduce here another evaluation plot and metric: the MPJPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_mpjpe\n",
    "\n",
    "loaded_predictor.test(dataset)\n",
    "plot_mpjpe(loaded_predictor, dataset, savefig_dir_path=model_dir / \"test_plots\")\n",
    "\n",
    "# We prepare our trajectory for input if a transformation is needed\n",
    "input_traj = test_traj.create_subtraj(\n",
    "    dataset.config.in_points,\n",
    "    dataset.config.in_features,\n",
    "    dataset.config.context_keys,\n",
    ")\n",
    "# we create a new predicted trajectory from a given predictor\n",
    "predicted_traj, pred_offset = predictor.predict_trajectory(\n",
    "    input_traj, future_size=dataset_config.future_size\n",
    ")\n",
    "plot_prediction_feature_wise(\n",
    "    truth_traj,\n",
    "    predicted_traj,\n",
    "    offset=pred_offset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Predictors\n",
    "\n",
    "in addition to the results you can check with tensorboard\n",
    "our plot methods have a plural variant used to compared trajectories and mpjpe results\n",
    "also we provide a runner method in evaluator to perform all we did upper with a list of trajectories and predictors, providing also a summary of the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_mpjpes, plot_trajectories_feature_wise\n",
    "from prescyent.evaluator.runners import eval_predictors, dump_eval_summary_list\n",
    "\n",
    "\n",
    "predictor_list = [loaded_predictor, baseline]\n",
    "\n",
    "plot_mpjpes(predictors=predictor_list, dataset=dataset)\n",
    "plot_trajectories_feature_wise(\n",
    "    [truth_traj, predicted_traj, baseline_traj],\n",
    "    [0, pred_offset, baseline_offset],\n",
    ")\n",
    "eval_summary_list = eval_predictors(\n",
    "    predictors=predictor_list,\n",
    "    trajectories=dataset.trajectories.test,\n",
    "    dataset_config=dataset.config,\n",
    "    future_size=None,  # will default to the future size in dataset_config\n",
    "    run_method=\"step_every_timestamp\",  # we run the predictor at each frame and retain the last predicted frame to create the predicted trajectory\n",
    "    do_plotting=True,  # you may want to disable theses or update the plotting function used as it is mainly made for low dim features (like Coordinates) and not too many points to plot\n",
    "    saveplot_dir_path=\"tests/plots\",\n",
    ")\n",
    "dump_eval_summary_list(\n",
    "    eval_summary_list, dump_dir=\"tests\", dump_prediction=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Surcharge the library with your own uses\n",
    "\n",
    "## Use the CustomDataset\n",
    "\n",
    "As long as you created the Trajectories object, you can benefit from the libs sampling and methods passing your trajectories to a CustomDataset (you just won't benefit from the AutoDataset).\n",
    "Note that for more permanent use of the library, you may prefer to create a new TrajectoryDataset instance with its own config class. Please check in the user documentation for more infos.\n",
    "\n",
    "### Features and conversions\n",
    "\n",
    "Example with a custom dataset having quaternions as trajectories that produces\n",
    "\n",
    "\n",
    "## Implement your own model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
