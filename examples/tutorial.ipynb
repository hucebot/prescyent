{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beforehand\n",
    "\n",
    "## Pre requisites\n",
    "\n",
    "Note that you may want to run this jupyter notebook in a virtual env !  \n",
    "To do so, create your environment with virtualenv or conda, activate it, install ipykernel and add your virtual environment to the jupyter kernels.  \n",
    "You should find all the necessary information here: https://janakiev.com/blog/jupyter-virtual-envs/  \n",
    "\n",
    "Here is what I personally did:  \n",
    "\n",
    "<details>\n",
    "    <summary>Click once on <font color=\"blue\"><b>this text</b></font> to show/hide the commands I used</summary>\n",
    "\n",
    "```bash\n",
    "    virtualenv .venv\n",
    "    source .venv/bin/activate\n",
    "    pip install ipykernel\n",
    "    python -m ipykernel install --name=venv_prescyent\n",
    "```\n",
    "</details>\n",
    "\n",
    "\n",
    "You should now edit and run this jupyter notebook in your browser, by running jupyter in your terminal with:  `jupyter notebook`  \n",
    "Or also run jupyters notebooks directly in vscode, selecting your newly created kernel instead of the current selection in the top right corner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "\n",
    "## Install the lib and download a dataset\n",
    "\n",
    "You should have all necessary information in the readme, and if not it's the perfect occasion to tell me !  \n",
    "Here we want to install the library from pypi, and load a dataset  \n",
    "Note that the pypi install of PreScyent install also all of its dependencies, including torch and cuda which can be long to install. You may want to install a custom version of torch beforehand that would still match the dependencies of PreScyent, so any torch above 2.0 (and bellow 3.0 if you are doing this tutorial from the future.)  \n",
    "In that case, choose a version of pytroch for your environment here: https://pytorch.org/get-started/locally/  \n",
    "\n",
    "\n",
    "The dataset we want to download is the TeleopIcub Dataset that you can find here: https://zenodo.org/records/5913573  \n",
    "or directly in its .hdf5 format here https://gitlab.inria.fr/hucebot/datasets/andydata-lab-prescientteleopicub (if you have the access rights)  \n",
    "\n",
    "If you have the original data from the zenodo website, you have to pre process it into the library's format to be able to load it and use it in the lib.  \n",
    "Again, please check the readme for the instructions !  \n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Click once on <font color=\"blue\"><b>this text</b></font> to show/hide the commands I used</summary>\n",
    "\n",
    "In the virualenv, install a specific version of torch instead of letting the library choose from its dependencies\n",
    "```bash\n",
    "    pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "```\n",
    "\n",
    "Install the lib from pypi\n",
    "```bash\n",
    "    pip install prescyent\n",
    "```\n",
    "\n",
    "Download and prepare dataset\n",
    "```bash\n",
    "    wget https://zenodo.org/records/5913573/files/AndyData-lab-prescientTeleopICub.zip\n",
    "    unzip AndyData-lab-prescientTeleopICub.zip -d AndyData-lab-prescientTeleopICub/\n",
    "    wget https://raw.githubusercontent.com/hucebot/prescyent/refs/heads/main/dataset_preprocessing/teleopicubdataset_to_hdf5.py\n",
    "    python teleopicubdataset_to_hdf5.py --data_path AndyData-lab-prescientTeleopICub/\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meet the Dataset and Trajectory\n",
    "\n",
    "Load the downloaded and processed dataset using the corresponding dataset class  \n",
    "\n",
    "\n",
    "We use Config classes for our main classes such as Datasets, Predictors, Scalers, or TrainingConfig for the Predictor's trainer  \n",
    "Such classes allows us to define default values and give some constraints or type hints about the possible inputs  \n",
    "If you use a code editor with auto_completion you'll have default values and types indicated, you can also refer to the user documentation for each config file here:  \n",
    "https://hucebot.github.io/prescyent/configuration_files.html  \n",
    "\n",
    "\n",
    "Update the dataset's config and see the corresponding generated tensor pairs and plots using the functions bellow !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_trajectory_feature_wise\n",
    "\n",
    "#? Load and import TeleopIcubDataset here\n",
    "#\n",
    "#   We expect dataset = ...\n",
    "#\n",
    "\n",
    "\n",
    "# Show shapes of data from the dataloaders as it'll be seen for the models\n",
    "input_tensor, context, output_tensor = next(iter(dataset.train_dataloader()))\n",
    "print(f\"#######################\")\n",
    "print(f\"TRAINING TENSOR SHAPES:\")\n",
    "print(f\"#######################\")\n",
    "print(f\"input_tensor as shapes {input_tensor.shape}\")\n",
    "print(f\"output_tensor as shapes {output_tensor.shape}\")\n",
    "for context_key, context_tensor in context.items():\n",
    "    print(f\"context {context_key} as shapes {context_tensor.shape}\")\n",
    "print(f\"#######################\")\n",
    "\n",
    "# Plot data from a test trajectory itself\n",
    "plot_trajectory_feature_wise(dataset.trajectories.test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Baselines on this dataset\n",
    "\n",
    "Now that you loaded a dataset, you want to run some predictors over it\n",
    "Let's meet the predictors with a very simple baseline, such as the ConstantPredictor or DelayedPredictor\n",
    "Instantiate one of theses baselines bellow and see the resulting prediction plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_prediction_feature_wise\n",
    "\n",
    "\n",
    "#? Load and import the ConstantPredictor baseline here\n",
    "#\n",
    "#  We expect baseline = ...\n",
    "#\n",
    "\n",
    "\n",
    "#? predict a new trajectory with the baseline\n",
    "#\n",
    "# We expect test_traj = ...\n",
    "#           baseline_traj = ...\n",
    "#           baseline_offset = ...\n",
    "#\n",
    "\n",
    "# we create a new predicted trajectory from a given predictor, built from the last predicted frame at each timestep\n",
    "baseline_traj, baseline_offset = ...\n",
    "\n",
    "\n",
    "#! Here we compare prediction with truth traj\n",
    "# subset a truth trajectory from the original traj if needed, to compare fairly with prediction\n",
    "truth_traj = test_traj.create_subtraj(\n",
    "    dataset.config.out_points, dataset.config.out_features\n",
    ")\n",
    "\n",
    "# plot prediction along truth\n",
    "plot_prediction_feature_wise(\n",
    "    truth_traj,\n",
    "    baseline_traj,\n",
    "    offset=baseline_offset,\n",
    ")\n",
    "#? TRY ALSO THE OTHER TWO BASELINES\n",
    "#? WHAT CAN YOU OBSERVE ABOUT THE PLOTS OF CONSTANT AND DELAYED BASELINES ?\n",
    "\n",
    "\n",
    "# Notice that the predicted trajectory doesn't start at T = future_size\n",
    "# Because we need to have an input of size history_size before predicting an output of size future_size\n",
    "# So actually the first predicted frame is at T = history_size + future_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train a Predictor model and save it\n",
    "\n",
    "Using our simplest architecture, the MlpPredictor we'll see how to train and save a ML Predictor, using high level methods based on the pytorch_lightning syntax.  \n",
    "\n",
    "Here you'll see that each of our ML Predictors as their own specific PredictorConfig, as they allow to customize their layers and behavior.  \n",
    "In addition to their config, to allow some training, you'll have to define a TrainingConfig object, again customizing the training process (number of epochs, early stopping patience, learning rate...)  \n",
    "\n",
    "It's also the moment to introduce the enums, such as LossFunctions or LearningTypes.  \n",
    "They are a standard we chose over Literals to describe a set of finite possibilities for a given config value, and define cleaner conditions based on theses values in the code instead of manipulating strings or another type.\n",
    "You'll find all of them importable from `prescyent.utils.enums`.  \n",
    "And more details about their values in the doc here: https://hucebot.github.io/prescyent/configuration_files.html  \n",
    "\n",
    "Once your model is trained, or during its training, you can monitor many training metrics using using tensorboard and providing the path to the directory where the model logs (defined by its configs' `save_path` argument, which default's value is \"data/models\"):\n",
    "`tensorboard --logdir data/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#? init and train a MlpPredictor with previous dataset\n",
    "#\n",
    "# We expect predictor = ...\n",
    "#\n",
    "\n",
    "# Save the predictor in an explicit directory describing the settings of the experiment\n",
    "model_dir = (\n",
    "    Path( \"tutorial\")\n",
    "    / \"models\"\n",
    "    / f\"{dataset.DATASET_NAME}\"\n",
    "    / f\"{predictor.name}\"\n",
    "    / f\"version_{predictor.version}\"\n",
    ")\n",
    "print(\"Model directory:\", model_dir)\n",
    "predictor.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load a model\n",
    "\n",
    "You can load a Predictor from disk using its static method `load_pretrained`. You must provide as argument the path to root directory of the model or directly to its config.json file.  \n",
    "Also when loading a Predictor from disk, you may choose on which `torch.device` you want to load your model's weights, by passing the device as an argument to the `load_pretrained` method of AutoPredictor or Predictor.  \n",
    "Remember that choosing the device is made through the `TrainingConfig.accelerator` attribute when you are creating a model from scratch.  \n",
    "The AutoPredictor class allows to load or build a Predictor based on its config file. The class has to be a class from the library in order for the AutoPredictor to function and recognize it (see in the user doc how to create a new predictor and add it to the AutoPredictor class).  \n",
    "It is perfect to generate an evaluation script that is agnostic to the actual class of predictor.  \n",
    "\n",
    "\n",
    "Note also that we still use the same loaded dataset, but the AutoDataset class also exists for the same purpose: reloading a Dataset used from a dataset_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? Load a predictor here\n",
    "#\n",
    "# We expect loaded_predictor =\n",
    "#\n",
    "\n",
    "# logs some infos about the predictor\n",
    "loaded_predictor.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Predictor\n",
    "\n",
    "We've seen qualitative evaluations with the previous work, here we'll introduce some quantitative metrics  \n",
    "First, we'll use the `test` method of the Predictor class to run the predictor over the whole test dataloader and return some metrics:  \n",
    "- ADE  \n",
    "- FDE  \n",
    "- MPJPE  \n",
    "\n",
    "Again you can monitor the results of such test method using tensorboard  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_mpjpe, plot_prediction_feature_wise\n",
    "\n",
    "#? Run the test method on your predictor, and use the two imported plot functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Predictors\n",
    "\n",
    "In addition to the results you can check with tensorboard\n",
    "our plot methods have a plural variant used to compared trajectories and mpjpe results.  \n",
    "Also we provide a runner method in evaluator to perform all we did upper with a list of trajectories and predictors, providing also a summary of the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prescyent.evaluator.plotting import plot_mpjpes, plot_trajectories_feature_wise\n",
    "from prescyent.evaluator.runners import eval_predictors, dump_eval_summary_list\n",
    "\n",
    "#? Use the methods imported above to compare Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Surcharge the library with your own uses\n",
    "\n",
    "## Use the CustomDataset\n",
    "\n",
    "As long as you created the Trajectories object, you can benefit from the libs sampling and methods passing your trajectories to a CustomDataset (you just won't benefit from the AutoDataset).\n",
    "Note that for more permanent use of the library, you may prefer to create a new TrajectoryDataset instance with its own config class. Please check in the user documentation for more infos.\n",
    "\n",
    "### Features and conversions\n",
    "\n",
    "Example with a custom dataset having quaternions as trajectories that produces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# This function creates a tensor with random quaternions and coordinates\n",
    "def create_random_traj(num_frames: int):\n",
    "    \"\"\"x,y,z are linear here and a constant random rotation is generated\"\"\"\n",
    "    linear_x_coordinates = torch.FloatTensor(np.linspace(0, 10, num_frames).tolist()).unsqueeze(0)\n",
    "    linear_y_coordinates = torch.FloatTensor(np.linspace(0, 10, num_frames).tolist()).unsqueeze(0)\n",
    "    linear_z_coordinates = torch.FloatTensor(np.linspace(0, 10, num_frames).tolist()).unsqueeze(0)\n",
    "    random_quat = R.random().as_quat()\n",
    "    random_quaternions = torch.FloatTensor([random_quat for _ in range(num_frames)])\n",
    "    tensor = torch.cat((linear_x_coordinates, linear_y_coordinates, linear_z_coordinates)).transpose(0, 1)\n",
    "    tensor = torch.cat((tensor, random_quaternions), dim=1)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    return tensor\n",
    "\n",
    "#? Create an instance of CustomDataset with generated Trajectories\n",
    "#\n",
    "# We expect custom_dataset = ...\n",
    "#\n",
    "\n",
    "#? Play with features and see the shapes of the tensors\n",
    "\n",
    "input_tensor, context, output_tensor = next(iter(custom_dataset.train_dataloader()))\n",
    "# Show shapes of data from the dataloaders as it'll be seen for the models\n",
    "print(f\"#######################\")\n",
    "print(f\"TRAINING TENSOR SHAPES:\")\n",
    "print(f\"#######################\")\n",
    "print(f\"input_tensor as shapes {input_tensor.shape}\")\n",
    "print(f\"output_tensor as shapes {output_tensor.shape}\")\n",
    "for context_key, context_tensor in context.items():\n",
    "    print(f\"context {context_key} as shapes {context_tensor.shape}\")\n",
    "print(f\"#######################\")\n",
    "# custom feature with distance function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your own model\n",
    "\n",
    "Create a torch module with a config and inherit from the base classes to create a custom predictor benefiting from common methods.  \n",
    "You can take example on the structure of a simple baseline such as the MlpPredictor.  \n",
    "\n",
    "Train it (and save it !)  \n",
    "Test it and and plot it as upper models  \n",
    "How does it compare ?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict\n",
    "import torch\n",
    "from prescyent.predictor.lightning.models.sequence.predictor import SequencePredictor\n",
    "from prescyent.predictor.lightning.configs.module_config import ModuleConfig\n",
    "from prescyent.predictor.lightning.torch_module import BaseTorchModule\n",
    "from prescyent.utils.tensor_manipulation import self_auto_batch\n",
    "\n",
    "\n",
    "class NewConfig(ModuleConfig):\n",
    "    \"\"\"New config for a lightning predictor with a torch module\"\"\"\n",
    "    # pass keys and values here that you may want to see vary in your architecture, like:\n",
    "    hidden_size: int = 128\n",
    "    # you can add more constraints on your config's attribute, like validators or min/max values\n",
    "    # see the Pydantic library's Documentation for more information, or check some examples in our code\n",
    "\n",
    "class NewTorchModule(BaseTorchModule):\n",
    "    \"\"\"New torch module inheriting from forward's decorator methods\n",
    "        create it's init and forward methods as any pytorch module !\n",
    "    \"\"\"\n",
    "    def __init__(self, config: NewConfig) -> None:\n",
    "        super().__init__(config)\n",
    "        # After the super().__init__(), you benefit from some infos from the config like theses:\n",
    "        self.in_size = self.out_sequence_size * self.num_out_points * self.num_out_dims\n",
    "        self.out_size = self.out_sequence_size * self.num_out_points * self.num_out_dims\n",
    "        #\n",
    "        # YOUR CODE HERE\n",
    "        #\n",
    "\n",
    "    @self_auto_batch  # <= auto batch the input, and unbatch the output if input tensor as only 3 shapes\n",
    "    @BaseTorchModule.deriv_tensor  # <= allows the behaviors described by`deriv_on_last_frame` and `deriv_output`\n",
    "    def forward(self, input_tensor: torch.Tensor, future_size: int=None, context: Dict[str, torch.Tensor] | None = None) -> torch.Tensor:\n",
    "        if future_size is None:  # future_size is optional for seq2seq predictors ! so if you intend to index on it, use this !\n",
    "            future_size = self.out_sequence_size\n",
    "        #\n",
    "        # YOUR CODE HERE\n",
    "        #\n",
    "\n",
    "class NewPredictor(SequencePredictor):\n",
    "    \"\"\"New class used to connect the config and torch module\n",
    "       while inheriting from all base methods\"\"\"\n",
    "\n",
    "    PREDICTOR_NAME = \"NewPredictor\"\n",
    "    \"\"\"unique name for this predictor\"\"\"\n",
    "    module_class = NewTorchModule\n",
    "    \"\"\"LightningModule class used in this predictor\"\"\"\n",
    "    config_class = NewConfig\n",
    "    \"\"\"PredictorConfig class used in this predictor\"\"\"\n",
    "\n",
    "    def __init__(self, config: NewConfig, skip_build: bool = False):\n",
    "        super().__init__(config=config, name=self.PREDICTOR_NAME, skip_build=skip_build)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
